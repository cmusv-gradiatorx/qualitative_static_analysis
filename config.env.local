# LLM Configuration
# Choose the LLM provider: gemini, openai, ollama
LLM_PROVIDER=ollama

# Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-pro

# OpenAI Configuration
OPENAI_API_KEY=openai_api_key_here
OPENAI_MODEL=gpt-4o
OPENAI_ORG_ID=

# Ollama Configuration (for local Llama models)
OLLAMA_BASE_URL=http://localhost:11434
#OLLAMA_MODEL=llama3.1
OLLAMA_MODEL=deepseek-r1

# Application Configuration
INPUT_FOLDER=input
OUTPUT_FOLDER=output
TEMP_FOLDER=temp

# Repomix Configuration (Global Defaults)
MAX_TOKENS=128000
USE_COMPRESSION=true
REMOVE_COMMENTS=false 

# Project Assignment Configuration
# Assignment-specific settings (semgrep, parallel processing) are defined in config/projects/[project_name].json
PROJECT_ASSIGNMENT=functional_programming_milestone_3 